
Meta-Llama model has been loaded....

 * Serving Flask app 'llama_engine'
 * Debug mode: on
[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:4040
[33mPress CTRL+C to quit[0m
 * Restarting with stat
 * Debugger is active!
 * Debugger PIN: 112-217-020
Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)
127.0.0.1 - - [23/Oct/2024 17:15:37] "POST /llama-engine HTTP/1.1" 200 -
127.0.0.1 - - [23/Oct/2024 17:16:46] "POST /llama-engine HTTP/1.1" 200 -
